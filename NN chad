
import numpy as np
import matplotlib.pyplot as plt
import random
import pandas as pd
import time
from sklearn import linear_model, datasets
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
import numpy as np
from sklearn.cross_validation  import train_test_split

datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        rescale=1./255,
        dim_ordering='th',
        fill_mode='nearest')


original_train_x = np.load("C:/Users/Dell/Documents/HEC/Session 2/Mcgill Machine Learning/Dev 3/tinyX.npy")
original_train_y = np.load("C:/Users/Dell/Documents/HEC/Session 2/Mcgill Machine Learning/Dev 3/tinyY.npy")

kaggle = np.load("C:/Users/Dell/Documents/HEC/Session 2/Mcgill Machine Learning/Dev 3/tinyX_test.npy")

idx = random.sample(range(np.size(original_train_y)), np.size(original_train_y))

#totX = original_train_x[idx]
#totY = original_train_y[idx] 

trainX, testX, trainY, testY = train_test_split(original_train_x, original_train_y, test_size=0.33, random_state=42)

del original_train_x, original_train_y

#i = 0
#tempX = temp.loc[temp.Y == i].head(140)
#i +=1
#while i < 40:
#    temp2 = temp.loc[temp.Y == i].head(140)
#    tempX = tempX.append(temp2)
#    i+=1

trainX2 = list(trainX)
trainY2 = list(trainY)

for j in range(2,40):
    a = np.array(np.where(trainY == j))
    b = np.array([trainX[z] for z in a])
    b = b[0, ...]
    a = a.T
    i = 0
    for X, Y in datagen.flow(b,a,batch_size=1):
        trainX2.append(X[0])
        trainY2.append(j)
        i+=1
        if i > 1000:
            break
   

np.save('trainX2_datagen', trainX2)
np.save('trainY2_datagen', trainY2)

trainX3 = np.array(trainX2)
trainY3 = np.array(trainY2)

#imatest = temp[temp.Y ==39]
#del imatest['Y']
#x = np.reshape(imatest.values, (len(imatest), 3, 64 ,64))
#i = 0
#for batch in datagen.flow(x, batch_size=1, ):
#    i += 1
#    if i > 2:
#        break  # otherwise the generator would loop indefinitely

trainY = tempX.Y.values
del tempX['Y']
trainX = tempX.values

testY = testX.Y.values
del testX['Y']
testX = testX.values



logreg = linear_model.LogisticRegression()


logreg.fit(trainX, trainY)

Z = logreg.predict(testX)

df = pd.DataFrame(Z)
df['class'] = testY

df['correct'] = np.where(df[0] == df['class'],1,0)

good_class_test = df.correct.mean()*100

submission = pd.DataFrame(logreg.predict(kaggle))

submission.columns = ['class']

submission.to_csv("C:/Users/Dell/Documents/HEC/Session 2/Mcgill Machine Learning/Dev 3/LogReg.csv")



trainX3, s, trainY3,ss = train_test_split(trainX3, trainY3, test_size=0.01, random_state=42)


from keras.layers import Conv2D, Reshape, Flatten, Dropout, BatchNormalization
from keras.models import Sequential
from keras.layers import Dense, Activation, MaxPooling2D , Input
from keras.optimizers import Adam
model = Sequential()


model.add(Reshape((3,64,64),  input_shape=(12288,)))
model.add(Conv2D(32, 3, 3, border_mode='same', subsample=(2,2), activation='relu'))
model.add(Conv2D(32, 3, 3, border_mode='same', subsample=(2,2), activation='relu'))
model.add(BatchNormalization())

model.add(Flatten())
model.add(Dense(output_dim=64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(output_dim=40, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])

#model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy'])

model.fit(trainX3.reshape(len(trainX3),12288), trainY3, nb_epoch=100)
model.fit(trainX.reshape(len(trainX), 12288), trainY, nb_epoch=10)


# test it!
validation_metrics = model.evaluate(testX.reshape(len(testX), 12288), testY)
print()
print(validation_metrics)

Z = model.predict(kaggle)

Z = pd.DataFrame(Z)
Z = pd.DataFrame(Z.idxmax(axis=1))
Z.columns = ['class']
Z.to_csv("C:/Users/Dell/Documents/HEC/Session 2/Mcgill Machine Learning/Dev 3/keras20e2cetadam.csv", index=True, index_label="id")



plt.imshow(trainX3[79500].transpose(2,1,0))






















